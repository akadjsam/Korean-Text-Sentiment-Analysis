{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## 모델 이어서 학습할 때\nimport pandas as pd\nimport re\nimport os\nimport torch\nimport json\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\n#from tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport numpy as np\nimport math\nfrom tqdm.notebook import tqdm\n\ndef clean_korean_text(text):\n    cleaned = re.sub(r'[^가-힣\\s]', '', str(text))\n    cleaned = re.sub(r'\\s+', ' ', cleaned)\n    return cleaned.strip()\n\ndef remove_stopwords(text, stopwords):\n    words = text.split()\n    filtered_words = [word for word in words if word not in stopwords]\n    return ' '.join(filtered_words)\n\ndef rating_to_sentiment(rating):\n    try:\n        rating = int(rating)\n        if rating == 5: return 3\n        elif rating == 4: return 2\n        elif rating == 2: return 1\n        elif rating == 1: return 0\n        else: return None\n    except:\n        return None\n\ndef preprocess_naver_shopping_data(file_path):\n    try:\n        df = pd.read_csv(file_path, sep='\\t', header=None, names=['rating', 'review'])\n        print(f\"총 {len(df)}개의 리뷰 로드 완료\")\n    except Exception as e:\n        print(f\"파일 로딩 오류: {e}\")\n        return None\n\n    print(\"텍스트 정제 중...\")\n    df['cleaned_review'] = df['review'].apply(clean_korean_text)\n    df = df[df['cleaned_review'].str.len() > 0]\n\n    print(\"중복 리뷰 제거 중...\")\n    before_dedup = len(df)\n    df = df.drop_duplicates(subset=['cleaned_review'], keep='first')\n    print(f\"{before_dedup - len(df)}개 중복 리뷰 제거 완료, {len(df)}개 남음\")\n\n    print(\"불용어 제거 중...\")\n    stopwords = ['은', '는', '이', '가', '고', '을', '를']\n    df['processed_review'] = df['cleaned_review'].apply(lambda x: remove_stopwords(x, stopwords))\n\n    print(\"감성 라벨 매핑 중...\")\n    df['sentiment_label'] = df['rating'].apply(rating_to_sentiment)\n    df = df.dropna(subset=['sentiment_label'])\n    df['sentiment_label'] = df['sentiment_label'].astype(int)\n\n    sentiment_counts = df['sentiment_label'].value_counts().sort_index()\n    sentiment_names = {0: '매우 부정적', 1: '부정적', 2: '긍정적', 3: '매우 긍정적'}\n    print(\"\\n감성 라벨 분포:\")\n    for label, count in sentiment_counts.items():\n        print(f\"  {sentiment_names[label]} ({label}): {count}개\")\n    return df\n\nclass ReviewDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ndef evaluate_model(model, data_loader, device):\n    \"\"\"모델 평가 함수\"\"\"\n    model.eval()\n    predictions = []\n    true_labels = []\n    total_loss = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_loss += loss.item()\n            \n            preds = torch.argmax(outputs.logits, dim=-1)\n            predictions.extend(preds.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(true_labels, predictions)\n    \n    return avg_loss, accuracy, true_labels, predictions\n\ndef save_checkpoint(model, tokenizer, optimizer, scheduler, epoch, best_val_acc, patience_counter, checkpoint_dir):\n    \"\"\"체크포인트 저장 함수 (스케줄러 포함)\"\"\"\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n    \n    # 모델과 토크나이저 저장\n    model.save_pretrained(checkpoint_dir)\n    tokenizer.save_pretrained(checkpoint_dir)\n    \n    # 학습 상태를 torch.save로 저장 (스케줄러 포함)\n    checkpoint_data = {\n        'epoch': epoch,\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n        'best_val_acc': best_val_acc,\n        'patience_counter': patience_counter\n    }\n    \n    torch.save(checkpoint_data, os.path.join(checkpoint_dir, 'training_state.pth'))\n    print(f\"체크포인트가 '{checkpoint_dir}'에 저장되었습니다.\")\n\ndef load_checkpoint(checkpoint_dir, device, total_steps=None):\n    \"\"\"체크포인트 로드 함수 (스케줄러 포함)\"\"\"\n    try:\n        # 모델과 토크나이저 로드\n        model = BertForSequenceClassification.from_pretrained(checkpoint_dir)\n        tokenizer = BertTokenizer.from_pretrained(checkpoint_dir)\n        \n        # 학습 상태를 torch.load로 로드\n        checkpoint_data = torch.load(os.path.join(checkpoint_dir, 'training_state.pth'), map_location=device, weights_only=False)\n\n        \n        model.to(device)\n        optimizer = AdamW(model.parameters(), lr=2e-5)  # 계속 학습시 낮은 learning rate\n        optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])\n        \n        # 스케줄러 로드\n        scheduler = None\n        if checkpoint_data.get('scheduler_state_dict') and total_steps:\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n            )\n            scheduler.load_state_dict(checkpoint_data['scheduler_state_dict'])\n        \n        # optimizer state 내 텐서들을 현재 디바이스로 이동\n        for state in optimizer.state.values():\n            for k, v in state.items():\n                if isinstance(v, torch.Tensor):\n                    state[k] = v.to(device)\n        \n        print(f\"체크포인트 로드 완료: 에폭 {checkpoint_data['epoch']}부터 재개\")\n        \n        return (model, tokenizer, optimizer, scheduler,\n                checkpoint_data['epoch'], \n                checkpoint_data['best_val_acc'], \n                checkpoint_data['patience_counter'])\n    \n    except Exception as e:\n        print(f\"체크포인트 로드 실패: {e}\")\n        return None\n\ndef save_data_split(train_texts, train_labels, val_texts, val_labels, test_texts, test_labels, save_path):\n    \"\"\"데이터 분할 결과 저장 (torch.save 사용)\"\"\"\n    data_split = {\n        'train_texts': train_texts,\n        'train_labels': train_labels,\n        'val_texts': val_texts,\n        'val_labels': val_labels,\n        'test_texts': test_texts,\n        'test_labels': test_labels\n    }\n    \n    torch.save(data_split, save_path)\n    print(f\"데이터 분할 결과가 '{save_path}'에 저장되었습니다.\")\n\ndef load_data_split(save_path):\n    \"\"\"저장된 데이터 분할 결과 로드 (torch.load 사용)\"\"\"\n    try:\n        data_split = torch.load(save_path, map_location='cpu')  # 데이터는 CPU에 로드\n        print(f\"저장된 데이터 분할을 '{save_path}'에서 로드했습니다.\")\n        return (data_split['train_texts'], data_split['train_labels'],\n                data_split['val_texts'], data_split['val_labels'],\n                data_split['test_texts'], data_split['test_labels'])\n    except Exception as e:\n        print(f\"저장된 데이터 분할 로드 실패: {e}\")\n        return None\n\n# ===================================================================\n# 메인 실행부 (체크포인트 지원 버전)\n# ===================================================================\nif __name__ == \"__main__\":\n    # --- 🚀 학습 설정 (필요에 따라 수정하세요) ---\n    USE_SCHEDULER = True\n    INITIAL_LR = 5e-5\n    CONTINUE_LR = 2e-5\n    batch_size = 32\n    # 체크포인트 관련 설정\n    USE_CHECKPOINT = True  # True: 체크포인트 사용, False: 새로 시작\n    CHECKPOINT_DIR = '/kaggle/input/bert/pytorch/epoch10/1/latest_checkpoint'\n    DATA_SPLIT_PATH = '/kaggle/input/data-split/data_split.pth'\n    # CHECKPOINT_DIR = '/kaggle/working/latest_checkpoint'  # 체크포인트 저장/로드 경로\n    # DATA_SPLIT_PATH = '/kaggle/working/data_split.pth'  # 데이터 분할 결과 저장 경로\n    \n    # 기본 학습 설정 (체크포인트가 없을 때 사용)\n    START_FROM_PRETRAINED = True  # True: 사전훈련 모델, False: 기존 학습된 모델\n    SAVED_MODEL_PATH = '/kaggle/input/epochs/20epochs'  # 기존 학습된 모델 경로(사용 x)\n    PRETRAINED_MODEL_NAME = 'bert-base-multilingual-cased'  # 사전훈련 모델명\n    \n    TARGET_TOTAL_EPOCHS = 30  # 최종 목표 에폭 수\n    EPOCHS_PER_SESSION = 20  # 한 세션당 학습할 에폭 수 (캐글 12시간 제한 고려)\n    \n    PROCESSED_FILE_PATH = '/kaggle/input/reviews/preprocessed_reviews.csv'\n    \n    # --- 💾 체크포인트 확인 및 로드 ---\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print(f\"사용 디바이스: {device}\")\n    \n    checkpoint_loaded = False\n    scheduler = None\n    \n    if USE_CHECKPOINT and os.path.exists(CHECKPOINT_DIR):\n        print(\"🔄 이전 체크포인트를 발견했습니다. 로드를 시도합니다...\")\n        \n        # 스케줄러 사용시 총 스텝 수 계산이 필요하므로 임시로 데이터 로드\n        if USE_SCHEDULER:\n            temp_df = pd.read_csv(PROCESSED_FILE_PATH)\n            temp_df = temp_df.dropna(subset=['processed_review', 'sentiment_label'])\n            train_size = int(len(temp_df) * 0.7)  # 학습 데이터 비율\n            total_steps = math.ceil(train_size / batch_size) * (TARGET_TOTAL_EPOCHS)  # batch_size=32 가정\n        else:\n            total_steps = None\n            \n        checkpoint_result = load_checkpoint(CHECKPOINT_DIR, device, total_steps)\n        \n        if checkpoint_result is not None:\n            model, tokenizer, optimizer, scheduler, last_epoch, best_val_acc, patience_counter = checkpoint_result\n            current_epoch = last_epoch + 1  # 다음 에폭부터 시작\n            checkpoint_loaded = True\n            print(f\"✅ 체크포인트 로드 성공! 에폭 {current_epoch}부터 재개합니다.\")\n            \n            # 저장된 데이터 분할 로드\n            data_split_result = load_data_split(DATA_SPLIT_PATH)\n            if data_split_result is not None:\n                train_texts, train_labels, val_texts, val_labels, test_texts, test_labels = data_split_result\n                print(\"✅ 이전 데이터 분할 결과를 사용합니다.\")\n            else:\n                print(\"❌ 데이터 분할 로드 실패. 새로 분할합니다.\")\n                checkpoint_loaded = False\n    \n    # --- 📊 데이터 준비 (체크포인트가 없는 경우) ---\n    if not checkpoint_loaded:\n        print(\"🆕 새로운 학습을 시작합니다...\")\n        \n        # 데이터 로드\n        print(f\"'{PROCESSED_FILE_PATH}'에서 전처리된 데이터를 불러옵니다.\")\n        processed_df = pd.read_csv(PROCESSED_FILE_PATH)\n        processed_df = processed_df.dropna(subset=['processed_review', 'sentiment_label'])\n        processed_df['sentiment_label'] = processed_df['sentiment_label'].astype(int)\n        print(f\"전체 데이터 개수: {len(processed_df)}\")\n        \n        # 데이터 분할\n        print(\"\\n데이터를 학습/검증/테스트 세트로 분할합니다...\")\n        train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n            processed_df['processed_review'].tolist(),\n            processed_df['sentiment_label'].tolist(),\n            test_size=0.3, random_state=42,\n            stratify=processed_df['sentiment_label']\n        )\n        \n        val_texts, test_texts, val_labels, test_labels = train_test_split(\n            temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n        )\n        \n        print(f\"학습 데이터: {len(train_texts)}개\")\n        print(f\"검증 데이터: {len(val_texts)}개\") \n        print(f\"테스트 데이터: {len(test_texts)}개\")\n        \n        # 데이터 분할 결과 저장\n        save_data_split(train_texts, train_labels, val_texts, val_labels, \n                       test_texts, test_labels, '/kaggle/working/data_split.pth')\n        \n        # 모델 및 토크나이저 로드\n        if START_FROM_PRETRAINED:\n            print(f\"사전훈련 모델 '{PRETRAINED_MODEL_NAME}'을 로드합니다.\")\n            tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n            model = BertForSequenceClassification.from_pretrained(\n                PRETRAINED_MODEL_NAME, num_labels=4\n            )\n            optimizer = AdamW(model.parameters(), lr=INITIAL_LR)\n        else:\n            print(f\"기존 학습된 모델 '{SAVED_MODEL_PATH}'을 로드합니다.\")\n            tokenizer = BertTokenizer.from_pretrained(SAVED_MODEL_PATH)\n            model = BertForSequenceClassification.from_pretrained(SAVED_MODEL_PATH)\n            optimizer = AdamW(model.parameters(), lr=CONTINUE_LR)\n        \n        model.to(device)\n        \n        # 🎯 학습률 스케줄러 설정\n        if USE_SCHEDULER:\n            train_size = len(train_texts)\n            total_steps = math.ceil(train_size / batch_size) * TARGET_TOTAL_EPOCHS  # batch_size=32\n            warmup_steps = int(0.1 * total_steps)  # 전체의 10%를 warmup\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n            )\n            print(f\"스케줄러 설정: 총 {total_steps} 스텝, 워밍업 {warmup_steps} 스텝\")\n        else:\n            scheduler = None\n        \n        current_epoch = 1\n        best_val_acc = 0.0\n        patience_counter = 0\n    \n    # --- 🔤 토큰화 및 데이터로더 준비 ---\n    print(\"\\n토큰화 진행 중...\")\n    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n    test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n    \n    train_dataset = ReviewDataset(train_encodings, train_labels)\n    val_dataset = ReviewDataset(val_encodings, val_labels)\n    test_dataset = ReviewDataset(test_encodings, test_labels)\n    \n    batch_size = 32\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    print(\"토큰화 및 데이터로더 준비 완료!\")\n    \n    # --- 📈 학습 시작 ---\n    end_epoch = min(current_epoch + EPOCHS_PER_SESSION - 1, TARGET_TOTAL_EPOCHS)\n    print(f\"\\n=== 모델 학습 시작 (에폭 {current_epoch}~{end_epoch}) ===\")\n    print(f\"최종 목표: {TARGET_TOTAL_EPOCHS} 에폭\")\n   \n    \n    patience = 5  # Early stopping patience\n    \n    for epoch_idx in range(EPOCHS_PER_SESSION):\n        if current_epoch > TARGET_TOTAL_EPOCHS:\n            print(f\"\\n🎉 목표 에폭 {TARGET_TOTAL_EPOCHS}에 도달했습니다!\")\n            break\n            \n        print(f\"\\nEpoch {current_epoch}/{TARGET_TOTAL_EPOCHS}\")\n        \n        # 학습\n        model.train()\n        train_loss = 0\n        loop = tqdm(train_loader, desc=f\"Training Epoch {current_epoch}\", leave=False)\n        \n        for batch in loop:\n            optimizer.zero_grad()\n            \n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            train_loss += loss.item()\n            \n            loss.backward()\n            optimizer.step()\n            \n            # 🎯 스케줄러 스텝 (사용하는 경우)\n            if scheduler:\n                scheduler.step()\n                current_lr = scheduler.get_last_lr()[0]\n                loop.set_postfix(loss=loss.item(), lr=f\"{current_lr:.2e}\")\n            else:\n                loop.set_postfix(loss=loss.item())\n        \n        avg_train_loss = train_loss / len(train_loader)\n        \n        # 검증\n        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, device)\n        \n        print(f\"학습 손실: {avg_train_loss:.4f}\")\n        print(f\"검증 손실: {val_loss:.4f}\")  \n        print(f\"검증 정확도: {val_acc:.4f}\")\n        \n        # Best model 업데이트\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            patience_counter = 0\n            \n            best_model_dir = f'/kaggle/working/best_sentiment_model'\n            if not os.path.exists(best_model_dir):\n                os.makedirs(best_model_dir)\n            model.save_pretrained(best_model_dir)\n            tokenizer.save_pretrained(best_model_dir)\n            print(f\"*** 새로운 최고 성능! 모델을 '{best_model_dir}'에 저장했습니다. ***\")\n        else:\n            patience_counter += 1\n            print(f\"성능 개선 없음. Patience: {patience_counter}/{patience}\")\n        \n        # 체크포인트 저장 (매 에폭마다)\n        save_checkpoint(model, tokenizer, optimizer, scheduler, current_epoch, best_val_acc, patience_counter, '/kaggle/working/latest_checkpoint')\n        \n        # Early stopping 체크\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping! {patience} 에폭 동안 성능 개선이 없었습니다.\")\n            break\n        \n        current_epoch += 1\n    \n    # --- 📊 세션 종료 시 상태 출력 ---\n    print(f\"\\n=== 현재 세션 완료 ===\")\n    print(f\"완료된 에폭: {current_epoch-1}/{TARGET_TOTAL_EPOCHS}\")\n    print(f\"최고 검증 정확도: {best_val_acc:.4f}\")\n    \n    if current_epoch <= TARGET_TOTAL_EPOCHS:\n        print(f\"\\n⏰ 다음 세션에서 에폭 {current_epoch}부터 재개하세요!\")\n        print(\"🔧 다음 세션 실행 시 설정:\")\n        print(\"   USE_CHECKPOINT = True\")\n        print(f\"   CHECKPOINT_DIR = '{CHECKPOINT_DIR}'\")\n    else:\n        print(\"\\n🎉 모든 학습이 완료되었습니다!\")\n        \n        # 최종 테스트 평가\n        print(\"\\n=== 최종 테스트 세트 평가 ===\")\n        best_model = BertForSequenceClassification.from_pretrained('/kaggle/working/best_sentiment_model')\n        best_model.to(device)\n        \n        test_loss, test_acc, test_true, test_pred = evaluate_model(best_model, test_loader, device)\n        print(f\"테스트 손실: {test_loss:.4f}\")\n        print(f\"테스트 정확도: {test_acc:.4f}\")\n        \n        # 상세한 분류 성능 리포트\n        print(\"\\n=== 상세 분류 성능 리포트 ===\")\n        target_names = ['매우 부정적', '부정적', '긍정적', '매우 긍정적']\n        print(classification_report(test_true, test_pred, target_names=target_names))\n    \n    print(\"\\n✅ 프로그램 종료\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertForSequenceClassification, BertTokenizer\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom tqdm import tqdm\nimport os\n\n# --------------------------------------------------------------------------\n# 1. 평가에 필요한 클래스와 함수 정의 (기존 코드에서 가져옴)\n# --------------------------------------------------------------------------\n\nclass ReviewDataset(Dataset):\n    \"\"\"PyTorch를 위한 커스텀 데이터셋 클래스\"\"\"\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # 모든 인코딩 값을 텐서로 변환\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        # 레이블도 텐서로 변환\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ndef evaluate_model(model, data_loader, device):\n    \"\"\"모델의 성능을 평가하고 예측 결과와 실제 값을 반환하는 함수\"\"\"\n    model.eval()  # 모델을 평가 모드로 설정\n    \n    predictions = []\n    true_labels = []\n    total_loss = 0\n    \n    with torch.no_grad():  # 그래디언트 계산 비활성화\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            # 데이터를 디바이스로 이동\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            # 모델 실행\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            \n            # 손실과 예측 결과 계산\n            loss = outputs.loss\n            total_loss += loss.item()\n            \n            preds = torch.argmax(outputs.logits, dim=-1)\n            \n            # 결과 저장\n            predictions.extend(preds.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n            \n    avg_loss = total_loss / len(data_loader)\n    accuracy = accuracy_score(true_labels, predictions)\n    \n    return avg_loss, accuracy, true_labels, predictions\n\ndef load_data_split(save_path):\n    \"\"\"저장된 데이터 분할 결과를 로드하는 함수\"\"\"\n    try:\n        data_split = torch.load(save_path, map_location='cpu')\n        print(f\"✅ '{save_path}'에서 데이터 분할 로드 완료.\")\n        return (data_split['train_texts'], data_split['train_labels'],\n                data_split['val_texts'], data_split['val_labels'],\n                data_split['test_texts'], data_split['test_labels'])\n    except Exception as e:\n        print(f\"❌ 데이터 분할 로드 실패: {e}\")\n        return None\n\n# --------------------------------------------------------------------------\n# 2. 메인 실행부\n# --------------------------------------------------------------------------\n\n# 🚨 **경로를 자신의 환경에 맞게 수정하세요!** 🚨\n# 가장 성능이 좋았던 모델 경로\nMODEL_PATH = '/kaggle/input/best_bert/pytorch/best_bert/1/best_sentiment_model'\n# 학습 시 분할해두었던 데이터 경로\nDATA_SPLIT_PATH = '/kaggle/input/data-split/data_split.pth'\n\n# --- 장치 설정 ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"사용 디바이스: {device}\")\n\n# --- 모델 및 토크나이저 로드 ---\nif not os.path.exists(MODEL_PATH):\n    print(f\"오류: '{MODEL_PATH}' 경로에 모델이 없습니다. 경로를 확인해주세요.\")\nelse:\n    print(f\"'{MODEL_PATH}'에서 모델과 토크나이저를 불러옵니다...\")\n    model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n    tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    print(\"모델 로딩 완료.\")\n\n    # --- 데이터 로드 및 준비 ---\n    if not os.path.exists(DATA_SPLIT_PATH):\n        print(f\"오류: '{DATA_SPLIT_PATH}' 경로에 데이터 파일이 없습니다. 경로를 확인해주세요.\")\n    else:\n        # 이전에 분할해 둔 데이터 로드 (학습/검증 데이터는 필요 없지만 test 데이터를 위해 로드)\n        _, _, _, _, test_texts, test_labels = load_data_split(DATA_SPLIT_PATH)\n\n        # 테스트 데이터 토큰화\n        print(\"테스트 데이터 토큰화 중...\")\n        test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n\n        # 데이터셋 및 데이터로더 생성\n        test_dataset = ReviewDataset(test_encodings, test_labels)\n        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n        print(\"데이터 준비 완료.\")\n\n        # --- 모델 평가 실행 ---\n        print(\"\\n🚀 모델 성능 평가를 시작합니다.\")\n        test_loss, test_acc, test_true, test_pred = evaluate_model(model, test_loader, device)\n\n        # --- 최종 결과 출력 ---\n        print(\"\\n📊 최종 평가 결과\")\n        print(\"=\"*30)\n        print(f\"테스트 손실 (Test Loss): {test_loss:.4f}\")\n        print(f\"테스트 정확도 (Test Accuracy): {test_acc:.4f}\")\n        print(\"=\"*30)\n\n        print(\"\\n📋 상세 분류 성능 리포트 (Classification Report)\")\n        target_names = ['매우 부정적 (0)', '부정적 (1)', '긍정적 (2)', '매우 긍정적 (3)']\n        print(classification_report(test_true, test_pred, target_names=target_names, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}